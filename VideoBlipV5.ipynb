{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip3 install salesforce-lavis\n",
        "!pip install openai"
      ],
      "metadata": {
        "id": "gbLSzi7rP9yy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBkF5mvFMIDX"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import math\n",
        "import torch\n",
        "from PIL import Image\n",
        "\n",
        "from lavis.models import load_model_and_preprocess\n",
        "from google.colab import files\n",
        "import os\n",
        "import openai\n",
        "openai.api_key = \"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\"\n",
        "# Configurar los parámetros para GPT-3\n",
        "model_engine = \"text-davinci-003\"\n",
        "max_length = 50\n",
        "top_p = 0\n",
        "n_best = 1\n",
        "temperature = 0\n",
        "batch_size = 16 #AJUSTAR SEGUN HARDWARE\n",
        "\n",
        "# Definir la ruta del directorio de entrada\n",
        "input_dir = \"/content/input\"\n",
        "\n",
        "# Definir la ruta del directorio de salida\n",
        "output_dir = \"/content/output\"\n",
        "\n",
        "# Crear el directorio de salida si no existe\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "os.makedirs(input_dir, exist_ok=True)\n",
        "\n",
        "# Permitir al usuario cargar varios archivos\n",
        "uploaded = files.upload()\n",
        "for name, data in uploaded.items():\n",
        "    with open(os.path.join(input_dir, name), \"wb\") as f:\n",
        "        f.write(data)\n",
        "\n",
        "# Obtener la lista de archivos de video en el directorio de entrada\n",
        "video_files = [os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith(\".mp4\")]\n",
        "\n",
        "\n",
        "for video_file in video_files:\n",
        "    # Obtener el nombre del archivo de video\n",
        "    video_filename = os.path.splitext(os.path.basename(video_file))[0]\n",
        "\n",
        "    # Definir la ruta de salida del archivo de texto\n",
        "    output_file = os.path.join(output_dir, \"predictions_\" + video_filename + \".txt\")\n",
        "\n",
        "    # Imprimir el nombre del archivo de video y el archivo de salida\n",
        "    print(\"Archivo cargado:\", video_filename)\n",
        "    print(\"Archivo de salida:\", output_file)\n",
        "\n",
        "    # Cargar el archivo de video\n",
        "    cap = cv2.VideoCapture(video_file)\n",
        "\n",
        "    # Obtener el número total de fotogramas en el video\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Crear una lista con los fotogramas que se desean extraer\n",
        "    frames_to_extract = [5, math.ceil(total_frames * 0.25), math.ceil(total_frames * 0.5), math.ceil(total_frames * 0.9), math.ceil(total_frames * 0.99) - 2]\n",
        "\n",
        "    # Iterar a través de cada fotograma para extraer y predecir\n",
        "    with open(output_file, \"w\") as f:\n",
        "        for frame_number in frames_to_extract:\n",
        "            # Establecer el fotograma actual y leer el cuadro\n",
        "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
        "            ret, frame = cap.read()\n",
        "\n",
        "            # Si el cuadro no se puede leer, salir del bucle\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            # Cargar el modelo BLIP\n",
        "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "            model, vis_processors, _ = load_model_and_preprocess(\n",
        "                name=\"blip_caption\", model_type=\"large_coco\", is_eval=True, device=device\n",
        "            )\n",
        "\n",
        "            # Preprocesar el cuadro para el modelo\n",
        "            preprocessed_frame = vis_processors[\"eval\"](Image.fromarray(frame)).unsqueeze(0).to(device)\n",
        "\n",
        "            # Generar la predicción del modelo en el cuadro\n",
        "            model_response = model.generate({\"image\": preprocessed_frame})[0]\n",
        "\n",
        "            # Escribir la predicción en el archivo de salida\n",
        "            f.write(f\"Frame {frame_number}: {model_response}\\n\")\n",
        "\n",
        "      # Leer las predicciones del archivo de salida\n",
        "    with open(output_file, 'r') as file:\n",
        "        text = file.read()\n",
        "    \n",
        "    # Agregar el nombre del video al prompt de OpenAI\n",
        "    prompt = text + f\"Video name is {video_file}. Video short description:\"\n",
        "    print(prompt)\n",
        "    \n",
        "    # Enviar el prompt a GPT-3 para completar la acción\n",
        "    response = openai.Completion.create(\n",
        "        engine=model_engine,\n",
        "        prompt=prompt,\n",
        "        max_tokens=max_length,\n",
        "        n=1,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0,\n",
        "        stop=None,\n",
        "        best_of=n_best\n",
        "    )\n",
        "    \n",
        "    # Obtener la respuesta de GPT-3\n",
        "    action = response.choices[0].text.strip()\n",
        "    \n",
        "    # Imprimir la acción sugerida por GPT-3\n",
        "    print(action)\n",
        "    \n",
        "    # Agregar la acción a la última línea del archivo de salida\n",
        "    with open(output_file, 'a') as file:\n",
        "        file.write(f\"{action}\\n\")\n",
        "\n",
        "# Cerrar el archivo de video\n",
        "    cap.release()\n",
        "\n",
        "print(\"Procesamiento completado.\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r output.zip /content/output\n",
        "from google.colab import video_files\n",
        "files.download('/content/output.zip')"
      ],
      "metadata": {
        "id": "bqvdYJ-zC60f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import os\n",
        "\n",
        "txt_folder = '/content/output'\n",
        "csv_file = '/content/output_data.csv'\n",
        "data = []\n",
        "\n",
        "for file_name in os.listdir(txt_folder):\n",
        "    if file_name.endswith('.txt'):\n",
        "      with open(os.path.join(txt_folder, file_name), 'r') as f:\n",
        "                lines = f.readlines()\n",
        "                name = file_name\n",
        "                second_line = lines[1].strip()\n",
        "                last_line = lines[-1].rstrip() if lines[-1].rstrip() else lines [-2].rstrip()\n",
        "                data.append([name, second_line, last_line])\n",
        "\n",
        "with open(csv_file, 'w', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerows(data)\n",
        "\n",
        "from google.colab import files\n",
        "files.download(csv_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Ntrj4OmZES00",
        "outputId": "38d5c46c-3f70-4d7d-f6c9-c574eeaa9ad2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7a8ab131-2141-4313-8fc5-784dfda033c8\", \"output_data.csv\", 14297)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -R /content/*"
      ],
      "metadata": {
        "id": "5Otb1khwNuOw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}