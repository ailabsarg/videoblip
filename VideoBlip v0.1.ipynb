{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# You first need to make a copy of this notebook in order to replace your API key in the code. Go to File ---> Save a copy in Drive."
      ],
      "metadata": {
        "id": "u8App-pqCf6h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbLSzi7rP9yy",
        "outputId": "748f4f41-55d1-4ecc-c10c-c5c1695e8f44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.8/dist-packages (0.27.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai) (2.25.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (4.0.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.8.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (3.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.3)\n"
          ]
        }
      ],
      "source": [
        "#@title \"Install the dependencies\"\n",
        "!pip3 install salesforce-lavis\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please change YOUR API KEY to your OpenAI API key."
      ],
      "metadata": {
        "id": "5FD5SJKRCNuS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBkF5mvFMIDX"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "import cv2\n",
        "import math\n",
        "import torch\n",
        "from PIL import Image\n",
        "\n",
        "from lavis.models import load_model_and_preprocess\n",
        "from google.colab import files\n",
        "import os\n",
        "import openai\n",
        "openai.api_key = \"YOUR API KEY\"\n",
        "## Configure the parameters for GPT-3\"\n",
        "model_engine = \"text-davinci-003\"\n",
        "max_length = 50\n",
        "top_p = 0\n",
        "n_best = 1\n",
        "temperature = 0\n",
        "batch_size = 16 ##### ADJUST ACCORDING TO HARDWARE!\n",
        "\n",
        "# Define the input directory path\n",
        "input_dir = \"/content/input\"\n",
        "\n",
        "# Define the output directory path\n",
        "output_dir = \"/content/output\"\n",
        "\n",
        "# Create the output directory if it does not exist\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "os.makedirs(input_dir, exist_ok=True)\n",
        "\n",
        "# Allow the user to upload multiple files\n",
        "uploaded = files.upload()\n",
        "for name, data in uploaded.items():\n",
        "    with open(os.path.join(input_dir, name), \"wb\") as f:\n",
        "        f.write(data)\n",
        "\n",
        "# Get the list of video files in the input directory\n",
        "video_files = [os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith(\".mp4\")]\n",
        "\n",
        "\n",
        "for video_file in video_files:\n",
        "    # Get the name of the video file\n",
        "    video_filename = os.path.splitext(os.path.basename(video_file))[0]\n",
        "\n",
        "    # Define the output text file path\n",
        "    output_file = os.path.join(output_dir, \"predictions_\" + video_filename + \".txt\")\n",
        "\n",
        "    # Print the video file name and output file\n",
        "    print(\"Archivo cargado:\", video_filename)\n",
        "    print(\"Archivo de salida:\", output_file)\n",
        "\n",
        "    # Load the video file\n",
        "    cap = cv2.VideoCapture(video_file)\n",
        "\n",
        "    # Get the total number of frames in the video\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Create a list with the frames to be extracted\n",
        "    frames_to_extract = [5, math.ceil(total_frames * 0.25), math.ceil(total_frames * 0.5), math.ceil(total_frames * 0.9), math.ceil(total_frames * 0.99) - 2]\n",
        "\n",
        "    # Iterate through each frame to extract and predict\n",
        "    with open(output_file, \"w\") as f:\n",
        "        for frame_number in frames_to_extract:\n",
        "            # set the current frame and read it\n",
        "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
        "            ret, frame = cap.read()\n",
        "\n",
        "            \n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            # load blip model\n",
        "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "            model, vis_processors, _ = load_model_and_preprocess(\n",
        "                name=\"blip_caption\", model_type=\"large_coco\", is_eval=True, device=device\n",
        "            )\n",
        "\n",
        "            # Preprocess the frame for the model\n",
        "            preprocessed_frame = vis_processors[\"eval\"](Image.fromarray(frame)).unsqueeze(0).to(device)\n",
        "\n",
        "            # Generate the model prediction on the frame\n",
        "            model_response = model.generate({\"image\": preprocessed_frame})[0]\n",
        "\n",
        "            # Write the prediction to the output file\n",
        "            f.write(f\"Frame {frame_number}: {model_response}\\n\")\n",
        "\n",
        "      # Read the predictions from the output file\n",
        "    with open(output_file, 'r') as file:\n",
        "        text = file.read()\n",
        "    \n",
        "    # Add the video name to the OpenAI prompt\n",
        "    prompt = text + f\"Video name is {video_file}. Video short description:\"\n",
        "    print(prompt)\n",
        "    \n",
        "    # Send the prompt to GPT-3 to complete the action\n",
        "    response = openai.Completion.create(\n",
        "        engine=model_engine,\n",
        "        prompt=prompt,\n",
        "        max_tokens=max_length,\n",
        "        n=1,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0,\n",
        "        stop=None,\n",
        "        best_of=n_best\n",
        "    )\n",
        "    \n",
        "    # Get the response from GPT-3\n",
        "    action = response.choices[0].text.strip()\n",
        "    \n",
        "    # Print the action suggested by GPT-3\n",
        "    print(action)\n",
        "    \n",
        "    # Add the action to the last line of the output file\n",
        "    with open(output_file, 'a') as file:\n",
        "        file.write(f\"{action}\\n\")\n",
        "\n",
        "# Close the video file\n",
        "    cap.release()\n",
        "\n",
        "print(\"Processing completed.\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqvdYJ-zC60f"
      },
      "outputs": [],
      "source": [
        "#@title zip and download files\n",
        "!zip -r output.zip /content/output\n",
        "from google.colab import video_files\n",
        "files.download('/content/output.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Ntrj4OmZES00",
        "outputId": "38d5c46c-3f70-4d7d-f6c9-c574eeaa9ad2"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_7a8ab131-2141-4313-8fc5-784dfda033c8\", \"output_data.csv\", 14297)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import csv\n",
        "import os\n",
        "\n",
        "txt_folder = '/content/output'\n",
        "csv_file = '/content/output_data.csv'\n",
        "data = []\n",
        "\n",
        "for file_name in os.listdir(txt_folder):\n",
        "    if file_name.endswith('.txt'):\n",
        "      with open(os.path.join(txt_folder, file_name), 'r') as f:\n",
        "                lines = f.readlines()\n",
        "                name = file_name\n",
        "                second_line = lines[1].strip()\n",
        "                last_line = lines[-1].rstrip() if lines[-1].rstrip() else lines [-2].rstrip()\n",
        "                data.append([name, second_line, last_line])\n",
        "\n",
        "with open(csv_file, 'w', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerows(data)\n",
        "\n",
        "from google.colab import files\n",
        "files.download(csv_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Otb1khwNuOw"
      },
      "outputs": [],
      "source": [
        "!rm -R /content/*"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}